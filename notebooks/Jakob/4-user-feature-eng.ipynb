{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b899d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STARTING FRESH: UNDERSTANDING OUR DATA\n",
      "======================================================================\n",
      "\n",
      "Dataset shape: (13735, 53)\n",
      "\n",
      "Columns we have:\n",
      "['id', 'Age', 'Gender', 'Reviews_Read', 'Price', 'Discount', 'Category', 'Items_In_Cart', 'Email_Interaction', 'Socioeconomic_Status_Score', 'Engagement_Score', 'AB_Bucket', 'Price_Sine', 'Day', 'Purchase', 'Time_of_Day_afternoon', 'Time_of_Day_evening', 'Time_of_Day_morning', 'Device_Type_desktop', 'Device_Type_mobile', 'Device_Type_tablet', 'Payment_Method_bank', 'Payment_Method_cash', 'Payment_Method_credit', 'Payment_Method_paypal', 'Referral_Source_ads', 'Referral_Source_direct', 'Referral_Source_email', 'Referral_Source_search_engine', 'Referral_Source_social_media', 'PM_RS_Combo_bank:ads', 'PM_RS_Combo_bank:direct', 'PM_RS_Combo_bank:email', 'PM_RS_Combo_bank:search_engine', 'PM_RS_Combo_bank:social_media', 'PM_RS_Combo_cash:ads', 'PM_RS_Combo_cash:direct', 'PM_RS_Combo_cash:email', 'PM_RS_Combo_cash:search_engine', 'PM_RS_Combo_cash:social_media', 'PM_RS_Combo_credit:ads', 'PM_RS_Combo_credit:direct', 'PM_RS_Combo_credit:email', 'PM_RS_Combo_credit:search_engine', 'PM_RS_Combo_credit:social_media', 'PM_RS_Combo_paypal:ads', 'PM_RS_Combo_paypal:direct', 'PM_RS_Combo_paypal:email', 'PM_RS_Combo_paypal:search_engine', 'PM_RS_Combo_paypal:social_media', 'Campaign_Period_false', 'Campaign_Period_true', 'Session_ID']\n",
      "\n",
      "üìä Target Distribution:\n",
      "Purchase\n",
      "0.0    8679\n",
      "1.0    5056\n",
      "Name: count, dtype: int64\n",
      "Purchase\n",
      "0.0    0.631889\n",
      "1.0    0.368111\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "üîç Data Types:\n",
      "float64    51\n",
      "int64       1\n",
      "object      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìà Numeric features (50):\n",
      "  - Age\n",
      "  - Gender\n",
      "  - Reviews_Read\n",
      "  - Price\n",
      "  - Discount\n",
      "  - Category\n",
      "  - Items_In_Cart\n",
      "  - Email_Interaction\n",
      "  - Socioeconomic_Status_Score\n",
      "  - Engagement_Score\n",
      "  - AB_Bucket\n",
      "  - Price_Sine\n",
      "  - Day\n",
      "  - Time_of_Day_afternoon\n",
      "  - Time_of_Day_evening\n",
      "  - Time_of_Day_morning\n",
      "  - Device_Type_desktop\n",
      "  - Device_Type_mobile\n",
      "  - Device_Type_tablet\n",
      "  - Payment_Method_bank\n",
      "  - Payment_Method_cash\n",
      "  - Payment_Method_credit\n",
      "  - Payment_Method_paypal\n",
      "  - Referral_Source_ads\n",
      "  - Referral_Source_direct\n",
      "  - Referral_Source_email\n",
      "  - Referral_Source_search_engine\n",
      "  - Referral_Source_social_media\n",
      "  - PM_RS_Combo_bank:ads\n",
      "  - PM_RS_Combo_bank:direct\n",
      "  - PM_RS_Combo_bank:email\n",
      "  - PM_RS_Combo_bank:search_engine\n",
      "  - PM_RS_Combo_bank:social_media\n",
      "  - PM_RS_Combo_cash:ads\n",
      "  - PM_RS_Combo_cash:direct\n",
      "  - PM_RS_Combo_cash:email\n",
      "  - PM_RS_Combo_cash:search_engine\n",
      "  - PM_RS_Combo_cash:social_media\n",
      "  - PM_RS_Combo_credit:ads\n",
      "  - PM_RS_Combo_credit:direct\n",
      "  - PM_RS_Combo_credit:email\n",
      "  - PM_RS_Combo_credit:search_engine\n",
      "  - PM_RS_Combo_credit:social_media\n",
      "  - PM_RS_Combo_paypal:ads\n",
      "  - PM_RS_Combo_paypal:direct\n",
      "  - PM_RS_Combo_paypal:email\n",
      "  - PM_RS_Combo_paypal:search_engine\n",
      "  - PM_RS_Combo_paypal:social_media\n",
      "  - Campaign_Period_false\n",
      "  - Campaign_Period_true\n",
      "\n",
      "üìã Categorical features (0):\n",
      "\n",
      "‚úÖ Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the cleaned & imputed dataset\n",
    "df = pd.read_csv('/Users/jakobbullinger/Documents/Coding Projects/DSBA/Intro Machine Learning/kaggle_competition/data/cleaned/df_imputed.csv', index_col=0)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING FRESH: UNDERSTANDING OUR DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns we have:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(f\"\\nüìä Target Distribution:\")\n",
    "print(df['Purchase'].value_counts())\n",
    "print(df['Purchase'].value_counts(normalize=True))\n",
    "\n",
    "print(f\"\\nüîç Data Types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Identify feature types\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove non-features\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['Purchase', 'id']]\n",
    "if 'Session_ID' in categorical_cols:\n",
    "    categorical_cols.remove('Session_ID')\n",
    "\n",
    "print(f\"\\nüìà Numeric features ({len(numeric_cols)}):\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(f\"\\nüìã Categorical features ({len(categorical_cols)}):\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"  - {col}\")\n",
    "    \n",
    "print(f\"\\n‚úÖ Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc36d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: VALIDATING EDA FINDINGS\n",
      "======================================================================\n",
      "\n",
      "üìä Baseline Purchase Rate: 0.368 (36.8%)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Finding 1: Reviews_Read Impact\n",
      "----------------------------------------------------------------------\n",
      "                     count      mean       lift\n",
      "Reviews_Read_Binned                            \n",
      "None                   687  0.177584 -51.758068\n",
      "Low(1)                2049  0.266471 -27.611049\n",
      "Medium(2-5)           9902  0.391436   6.336520\n",
      "High(5+)              1097  0.466727  26.789980\n",
      "\n",
      "EDA claimed: +163% lift\n",
      "We observe: Max lift = 26.8%\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Finding 2: Email_Interaction Impact\n",
      "----------------------------------------------------------------------\n",
      "Email_Interaction is numeric (already encoded)\n",
      "                   count      mean        lift\n",
      "Email_Interaction                             \n",
      "0.000000            7352  0.315424  -14.312623\n",
      "0.145578               1  1.000000  171.657437\n",
      "0.152468               1  0.000000 -100.000000\n",
      "0.156383               1  0.000000 -100.000000\n",
      "0.157494               1  0.000000 -100.000000\n",
      "...                  ...       ...         ...\n",
      "0.822169               1  0.000000 -100.000000\n",
      "0.827134               1  0.000000 -100.000000\n",
      "0.831387               1  1.000000  171.657437\n",
      "0.834658               1  1.000000  171.657437\n",
      "1.000000            6135  0.428525   16.411964\n",
      "\n",
      "[250 rows x 3 columns]\n",
      "\n",
      "EDA claimed: +36% lift\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Finding 3: Device_Type Impact\n",
      "----------------------------------------------------------------------\n",
      "Device columns found: ['Device_Type_desktop', 'Device_Type_mobile', 'Device_Type_tablet']\n",
      "Device_Type_desktop: 0.403 (+9.4% lift)\n",
      "Device_Type_mobile: 0.319 (-13.3% lift)\n",
      "Device_Type_tablet: 0.431 (+17.2% lift)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Finding 4: Email √ó Campaign Interaction\n",
      "----------------------------------------------------------------------\n",
      "Campaign columns found: ['Campaign_Period_false', 'Campaign_Period_true']\n",
      "              Segment  Count  Purchase_Rate     Lift_%\n",
      "No Email, No Campaign   4726       0.279518 -24.066975\n",
      "           Email Only   3907       0.391605   6.382359\n",
      "        Campaign Only   2626       0.380046   3.242240\n",
      "     Email √ó Campaign   2228       0.493268  33.999786\n",
      "\n",
      "EDA claimed: +78% combined lift\n",
      "We observe: 34.0% lift\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Finding 5: Category Impact\n",
      "----------------------------------------------------------------------\n",
      "          count      mean        lift\n",
      "Category                             \n",
      "0.000000   2690  0.426022   15.732127\n",
      "0.586418      1  1.000000  171.657437\n",
      "0.599693      1  0.000000 -100.000000\n",
      "0.606759      1  1.000000  171.657437\n",
      "0.659147      1  0.000000 -100.000000\n",
      "...         ...       ...         ...\n",
      "3.391989      1  0.000000 -100.000000\n",
      "3.401994      1  0.000000 -100.000000\n",
      "3.406951      1  0.000000 -100.000000\n",
      "3.815923      1  0.000000 -100.000000\n",
      "4.000000   2771  0.293396  -20.296826\n",
      "\n",
      "[292 rows x 3 columns]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Finding 6 & 7: Variables with NO Signal\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Age purchase rates:\n",
      "Age\n",
      "<30      0.366706\n",
      "30-40    0.370048\n",
      "40-50    0.369550\n",
      "50+      0.369780\n",
      "Name: Purchase, dtype: float64\n",
      "Std dev: 0.0016 (low = flat signal)\n",
      "\n",
      "AB_Bucket purchase rates:\n",
      "AB_Bucket\n",
      "0.000000    0.372069\n",
      "0.515385    0.000000\n",
      "0.629134    1.000000\n",
      "0.982113    1.000000\n",
      "1.000000    0.372167\n",
      "              ...   \n",
      "4.840603    0.000000\n",
      "5.000000    0.373424\n",
      "5.004713    1.000000\n",
      "5.150954    1.000000\n",
      "6.000000    0.371341\n",
      "Name: Purchase, Length: 276, dtype: float64\n",
      "Std dev: 0.4816 (low = flat signal)\n",
      "\n",
      "======================================================================\n",
      "VALIDATION COMPLETE\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/s4899s557wd3yl88tyql43dm0000gn/T/ipykernel_60737/2520211271.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  reviews_analysis = df.groupby('Reviews_Read_Binned')['Purchase'].agg(['count', 'mean'])\n",
      "/var/folders/zw/s4899s557wd3yl88tyql43dm0000gn/T/ipykernel_60737/2520211271.py:139: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  age_analysis = df.groupby(age_bins)['Purchase'].mean()\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: VALIDATING EDA FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate baseline purchase rate\n",
    "baseline_rate = df['Purchase'].mean()\n",
    "print(f\"\\nüìä Baseline Purchase Rate: {baseline_rate:.3f} ({baseline_rate*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Finding 1: Reviews_Read (+163% lift)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Finding 1: Reviews_Read Impact\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Create bins for Reviews_Read\n",
    "df['Reviews_Read_Binned'] = pd.cut(df['Reviews_Read'], \n",
    "                                   bins=[-0.1, 0, 1, 5, 100], \n",
    "                                   labels=['None', 'Low(1)', 'Medium(2-5)', 'High(5+)'])\n",
    "\n",
    "reviews_analysis = df.groupby('Reviews_Read_Binned')['Purchase'].agg(['count', 'mean'])\n",
    "reviews_analysis['lift'] = (reviews_analysis['mean'] / baseline_rate - 1) * 100\n",
    "\n",
    "print(reviews_analysis)\n",
    "print(f\"\\nEDA claimed: +163% lift\")\n",
    "print(f\"We observe: Max lift = {reviews_analysis['lift'].max():.1f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# Finding 2: Email_Interaction (+36% lift)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Finding 2: Email_Interaction Impact\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Check if Email_Interaction is encoded or text\n",
    "if df['Email_Interaction'].dtype == 'object':\n",
    "    print(\"Email_Interaction is categorical (text)\")\n",
    "    print(df['Email_Interaction'].value_counts())\n",
    "else:\n",
    "    print(\"Email_Interaction is numeric (already encoded)\")\n",
    "\n",
    "email_analysis = df.groupby('Email_Interaction')['Purchase'].agg(['count', 'mean'])\n",
    "email_analysis['lift'] = (email_analysis['mean'] / baseline_rate - 1) * 100\n",
    "\n",
    "print(email_analysis)\n",
    "print(f\"\\nEDA claimed: +36% lift\")\n",
    "if len(email_analysis) == 2:\n",
    "    print(f\"We observe: {email_analysis['lift'].iloc[1]:.1f}% lift\")\n",
    "\n",
    "# ============================================================================\n",
    "# Finding 3: Device_Type (+27% lift)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Finding 3: Device_Type Impact\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Check which device type columns exist\n",
    "device_cols = [col for col in df.columns if 'Device_Type' in col]\n",
    "print(f\"Device columns found: {device_cols}\")\n",
    "\n",
    "if len(device_cols) > 0:\n",
    "    # Already one-hot encoded\n",
    "    for device_col in device_cols:\n",
    "        device_rate = df[df[device_col] == 1]['Purchase'].mean()\n",
    "        lift = (device_rate / baseline_rate - 1) * 100\n",
    "        print(f\"{device_col}: {device_rate:.3f} ({lift:+.1f}% lift)\")\n",
    "else:\n",
    "    # Not encoded yet\n",
    "    device_analysis = df.groupby('Device_Type')['Purchase'].agg(['count', 'mean'])\n",
    "    device_analysis['lift'] = (device_analysis['mean'] / baseline_rate - 1) * 100\n",
    "    print(device_analysis)\n",
    "\n",
    "# ============================================================================\n",
    "# Finding 4: Email √ó Campaign (+78% combined lift)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Finding 4: Email √ó Campaign Interaction\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Check campaign columns\n",
    "campaign_cols = [col for col in df.columns if 'Campaign' in col]\n",
    "print(f\"Campaign columns found: {campaign_cols}\")\n",
    "\n",
    "# Create interaction variable\n",
    "if 'Campaign_Period_true' in df.columns:\n",
    "    campaign_indicator = df['Campaign_Period_true']\n",
    "elif 'Campaign_Period' in df.columns:\n",
    "    campaign_indicator = df['Campaign_Period']\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No campaign column found!\")\n",
    "    campaign_indicator = None\n",
    "\n",
    "if campaign_indicator is not None:\n",
    "    # Email during campaign\n",
    "    email_campaign = (df['Email_Interaction'] == 1) & (campaign_indicator == 1)\n",
    "    \n",
    "    interaction_analysis = pd.DataFrame({\n",
    "        'Segment': ['No Email, No Campaign', 'Email Only', 'Campaign Only', 'Email √ó Campaign'],\n",
    "        'Count': [\n",
    "            ((df['Email_Interaction'] == 0) & (campaign_indicator == 0)).sum(),\n",
    "            ((df['Email_Interaction'] == 1) & (campaign_indicator == 0)).sum(),\n",
    "            ((df['Email_Interaction'] == 0) & (campaign_indicator == 1)).sum(),\n",
    "            email_campaign.sum()\n",
    "        ],\n",
    "        'Purchase_Rate': [\n",
    "            df[(df['Email_Interaction'] == 0) & (campaign_indicator == 0)]['Purchase'].mean(),\n",
    "            df[(df['Email_Interaction'] == 1) & (campaign_indicator == 0)]['Purchase'].mean(),\n",
    "            df[(df['Email_Interaction'] == 0) & (campaign_indicator == 1)]['Purchase'].mean(),\n",
    "            df[email_campaign]['Purchase'].mean()\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    interaction_analysis['Lift_%'] = (interaction_analysis['Purchase_Rate'] / baseline_rate - 1) * 100\n",
    "    print(interaction_analysis.to_string(index=False))\n",
    "    print(f\"\\nEDA claimed: +78% combined lift\")\n",
    "    print(f\"We observe: {interaction_analysis.iloc[3]['Lift_%']:.1f}% lift\")\n",
    "\n",
    "# ============================================================================\n",
    "# Finding 5: Category (+14% lift)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Finding 5: Category Impact\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "if 'Category' in df.columns:\n",
    "    category_analysis = df.groupby('Category')['Purchase'].agg(['count', 'mean'])\n",
    "    category_analysis['lift'] = (category_analysis['mean'] / baseline_rate - 1) * 100\n",
    "    print(category_analysis)\n",
    "\n",
    "# ============================================================================\n",
    "# Finding 6 & 7: Age and AB_Bucket (NO signal)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Finding 6 & 7: Variables with NO Signal\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "if 'Age' in df.columns:\n",
    "    age_bins = pd.cut(df['Age'], bins=[0, 30, 40, 50, 100], labels=['<30', '30-40', '40-50', '50+'])\n",
    "    age_analysis = df.groupby(age_bins)['Purchase'].mean()\n",
    "    print(f\"\\nAge purchase rates:\\n{age_analysis}\")\n",
    "    print(f\"Std dev: {age_analysis.std():.4f} (low = flat signal)\")\n",
    "\n",
    "if 'AB_Bucket' in df.columns:\n",
    "    ab_analysis = df.groupby('AB_Bucket')['Purchase'].mean()\n",
    "    print(f\"\\nAB_Bucket purchase rates:\\n{ab_analysis}\")\n",
    "    print(f\"Std dev: {ab_analysis.std():.4f} (low = flat signal)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d029d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUICK FIX: Convert problematic features to binary\n",
      "======================================================================\n",
      "\n",
      "Email_Interaction unique values: 250\n",
      "Sample values: Email_Interaction\n",
      "0.000000    7352\n",
      "1.000000    6135\n",
      "0.433172       1\n",
      "0.664845       1\n",
      "0.203583       1\n",
      "0.609830       1\n",
      "0.367239       1\n",
      "0.394678       1\n",
      "0.419264       1\n",
      "0.228377       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Email_Engaged distribution:\n",
      "Email_Engaged\n",
      "0    7508\n",
      "1    6227\n",
      "Name: count, dtype: int64\n",
      "Purchase rate by Email_Engaged:\n",
      "Email_Engaged\n",
      "0    0.317528\n",
      "1    0.429099\n",
      "Name: Purchase, dtype: float64\n",
      "\n",
      "Category unique values: 292\n",
      "Category_Clean distribution:\n",
      "Category_Clean\n",
      "1    2845\n",
      "4    2772\n",
      "2    2763\n",
      "0    2690\n",
      "3    2665\n",
      "Name: count, dtype: int64\n",
      "Purchase rate by Category:\n",
      "Category_Clean\n",
      "0    0.426022\n",
      "1    0.400351\n",
      "2    0.410785\n",
      "3    0.308818\n",
      "4    0.293290\n",
      "Name: Purchase, dtype: float64\n",
      "\n",
      "‚úÖ Saved: df_imputed_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('/Users/jakobbullinger/Documents/Coding Projects/DSBA/Intro Machine Learning/kaggle_competition/data/cleaned/df_imputed.csv', index_col=0)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"QUICK FIX: Convert problematic features to binary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Fix Email_Interaction - make it binary\n",
    "print(\"\\nEmail_Interaction unique values:\", df['Email_Interaction'].nunique())\n",
    "print(\"Sample values:\", df['Email_Interaction'].value_counts().head(10))\n",
    "\n",
    "# Convert to binary (1 if > 0, else 0)\n",
    "df['Email_Engaged'] = (df['Email_Interaction'] > 0.5).astype(int)\n",
    "print(f\"\\nEmail_Engaged distribution:\\n{df['Email_Engaged'].value_counts()}\")\n",
    "print(f\"Purchase rate by Email_Engaged:\\n{df.groupby('Email_Engaged')['Purchase'].mean()}\")\n",
    "\n",
    "# Fix Category - round to nearest integer\n",
    "print(\"\\nCategory unique values:\", df['Category'].nunique())\n",
    "df['Category_Clean'] = df['Category'].round().astype(int)\n",
    "print(f\"Category_Clean distribution:\\n{df['Category_Clean'].value_counts()}\")\n",
    "print(f\"Purchase rate by Category:\\n{df.groupby('Category_Clean')['Purchase'].mean()}\")\n",
    "\n",
    "# Drop original messy columns\n",
    "df = df.drop(['Email_Interaction', 'Category'], axis=1)\n",
    "\n",
    "# Save cleaned version\n",
    "df.to_csv('df_imputed_fixed.csv')\n",
    "print(\"\\n‚úÖ Saved: df_imputed_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b0247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features: 50\n",
      "Samples: 13735\n",
      "\n",
      "üìä BASELINE PERFORMANCE\n",
      "Best F1: 0.8117 at threshold 0.43\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.945     0.797     0.865      1736\n",
      "         1.0      0.726     0.921     0.812      1011\n",
      "\n",
      "    accuracy                          0.843      2747\n",
      "   macro avg      0.835     0.859     0.838      2747\n",
      "weighted avg      0.864     0.843     0.845      2747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop(['Purchase', 'id', 'Session_ID'], axis=1, errors='ignore')\n",
    "y = df['Purchase']\n",
    "\n",
    "print(f\"\\nFeatures: {X.shape[1]}\")\n",
    "print(f\"Samples: {len(X)}\")\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train simple XGBoost\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=1.72,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Find best threshold\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for thresh in np.arange(0.3, 0.7, 0.01):\n",
    "    y_pred = (y_pred_proba >= thresh).astype(int)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(f\"\\nüìä BASELINE PERFORMANCE\")\n",
    "print(f\"Best F1: {best_f1:.4f} at threshold {best_thresh:.2f}\")\n",
    "\n",
    "y_pred_final = (y_pred_proba >= best_thresh).astype(int)\n",
    "print(\"\\n\", classification_report(y_val, y_pred_final, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44db696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Email_Campaign_Interaction distribution:\n",
      "Email_Campaign_Interaction\n",
      "0    11472\n",
      "1     2263\n",
      "Name: count, dtype: int64\n",
      "Purchase rate: 0.494\n",
      "\n",
      "üìä WITH EMAIL√óCAMPAIGN FEATURE\n",
      "Best F1: 0.8175 (vs baseline 0.8117)\n",
      "Improvement: +0.0058\n",
      "‚úÖ Feature helped!\n"
     ]
    }
   ],
   "source": [
    "# Create interaction feature\n",
    "if 'Campaign_Period_true' in df.columns:\n",
    "    df['Email_Campaign_Interaction'] = (\n",
    "        (df['Email_Engaged'] == 1) & \n",
    "        (df['Campaign_Period_true'] == 1)\n",
    "    ).astype(int)\n",
    "    \n",
    "    print(f\"\\nEmail_Campaign_Interaction distribution:\")\n",
    "    print(df['Email_Campaign_Interaction'].value_counts())\n",
    "    print(f\"Purchase rate: {df[df['Email_Campaign_Interaction']==1]['Purchase'].mean():.3f}\")\n",
    "\n",
    "# Retrain with new feature\n",
    "X_enhanced = df.drop(['Purchase', 'id', 'Session_ID'], axis=1, errors='ignore')\n",
    "y = df['Purchase']\n",
    "\n",
    "X_train_enh, X_val_enh, y_train_enh, y_val_enh = train_test_split(\n",
    "    X_enhanced, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model_enh = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=1.72,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_enh.fit(X_train_enh, y_train_enh)\n",
    "\n",
    "y_pred_proba_enh = model_enh.predict_proba(X_val_enh)[:, 1]\n",
    "\n",
    "# Find best threshold\n",
    "best_f1_enh = 0\n",
    "best_thresh_enh = 0.5\n",
    "\n",
    "for thresh in np.arange(0.3, 0.7, 0.01):\n",
    "    y_pred = (y_pred_proba_enh >= thresh).astype(int)\n",
    "    f1 = f1_score(y_val_enh, y_pred)\n",
    "    if f1 > best_f1_enh:\n",
    "        best_f1_enh = f1\n",
    "        best_thresh_enh = thresh\n",
    "\n",
    "print(f\"\\nüìä WITH EMAIL√óCAMPAIGN FEATURE\")\n",
    "print(f\"Best F1: {best_f1_enh:.4f} (vs baseline {best_f1:.4f})\")\n",
    "print(f\"Improvement: {best_f1_enh - best_f1:+.4f}\")\n",
    "\n",
    "if best_f1_enh > best_f1:\n",
    "    print(\"‚úÖ Feature helped!\")\n",
    "else:\n",
    "    print(\"‚ùå Feature didn't help - stick with baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8946bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTING ADDITIONAL VALIDATED FEATURES\n",
      "======================================================================\n",
      "Current features: 53\n",
      "\n",
      "1Ô∏è‚É£ Reviews_Read_Any:\n",
      "   Distribution: {1: 13048, 0: 687}\n",
      "   Purchase rate: 0.378 (baseline: 0.368)\n",
      "   Lift: +2.7%\n",
      "\n",
      "2Ô∏è‚É£ Is_Tablet_User:\n",
      "   Distribution: {0.0: 11730, 1.0: 2005}\n",
      "   Purchase rate: 0.431\n",
      "   Lift: +17.2%\n",
      "\n",
      "3Ô∏è‚É£ High_Engagement_Shopper (Reviews + Cart):\n",
      "   Distribution: {1: 11889, 0: 1846}\n",
      "   Purchase rate: 0.331\n",
      "   Lift: -10.1%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Load fixed data\n",
    "df = pd.read_csv('df_imputed_fixed.csv', index_col=0)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TESTING ADDITIONAL VALIDATED FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Current features we have\n",
    "print(f\"Current features: {df.shape[1]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Feature 1: Reviews_Read_Binary (+27% lift validated)\n",
    "# ============================================================================\n",
    "df['Reviews_Read_Any'] = (df['Reviews_Read'] > 0).astype(int)\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£ Reviews_Read_Any:\")\n",
    "print(f\"   Distribution: {df['Reviews_Read_Any'].value_counts().to_dict()}\")\n",
    "read_rate = df[df['Reviews_Read_Any'] == 1]['Purchase'].mean()\n",
    "baseline = df['Purchase'].mean()\n",
    "print(f\"   Purchase rate: {read_rate:.3f} (baseline: {baseline:.3f})\")\n",
    "print(f\"   Lift: {(read_rate/baseline - 1)*100:+.1f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# Feature 2: Device_Is_Tablet (+17% lift validated)\n",
    "# ============================================================================\n",
    "if 'Device_Type_tablet' in df.columns:\n",
    "    df['Is_Tablet_User'] = df['Device_Type_tablet']\n",
    "    tablet_rate = df[df['Is_Tablet_User'] == 1]['Purchase'].mean()\n",
    "    print(f\"\\n2Ô∏è‚É£ Is_Tablet_User:\")\n",
    "    print(f\"   Distribution: {df['Is_Tablet_User'].value_counts().to_dict()}\")\n",
    "    print(f\"   Purchase rate: {tablet_rate:.3f}\")\n",
    "    print(f\"   Lift: {(tablet_rate/baseline - 1)*100:+.1f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# Feature 3: High_Engagement_Shopper (Reviews + Items in Cart)\n",
    "# ============================================================================\n",
    "# Combining two signals: reads reviews AND has items in cart\n",
    "df['High_Engagement_Shopper'] = (\n",
    "    (df['Reviews_Read'] > 0) & \n",
    "    (df['Items_In_Cart'] > 0)\n",
    ").astype(int)\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£ High_Engagement_Shopper (Reviews + Cart):\")\n",
    "print(f\"   Distribution: {df['High_Engagement_Shopper'].value_counts().to_dict()}\")\n",
    "engaged_rate = df[df['High_Engagement_Shopper'] == 1]['Purchase'].mean()\n",
    "print(f\"   Purchase rate: {engaged_rate:.3f}\")\n",
    "print(f\"   Lift: {(engaged_rate/baseline - 1)*100:+.1f}%\")\n",
    "\n",
    "# ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c0e4dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1880423804.py, line 124)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 124\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m``\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('/Users/jakobbullinger/Documents/Coding Projects/DSBA/Intro Machine Learning/kaggle_competition/notebooks/Jakob/df_imputed_fixed.csv', index_col=0)\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING WITH ONLY GOOD FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Add only features that showed positive lift\n",
    "df['Email_Campaign_Interaction'] = (\n",
    "    (df['Email_Engaged'] == 1) & \n",
    "    (df['Campaign_Period_true'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Tablet user is already encoded as Device_Type_tablet, no need to add\n",
    "\n",
    "print(f\"‚úÖ Added 1 engineered feature: Email_Campaign_Interaction\")\n",
    "print(f\"‚úÖ Using existing feature: Device_Type_tablet (+17% lift)\")\n",
    "\n",
    "# Prepare data\n",
    "feature_cols = [col for col in df.columns \n",
    "                if col not in ['Purchase', 'id', 'Session_ID']]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['Purchase']\n",
    "\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train with regularization\n",
    "model = XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=1.72,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Find optimal threshold\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for thresh in np.arange(0.3, 0.7, 0.01):\n",
    "    y_pred = (y_pred_proba >= thresh).astype(int)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(f\"\\nüìä PERFORMANCE\")\n",
    "print(f\"Best F1: {best_f1:.4f} at threshold {best_thresh:.2f}\")\n",
    "\n",
    "y_pred_final = (y_pred_proba >= best_thresh).astype(int)\n",
    "print(\"\\n\", classification_report(y_val, y_pred_final, digits=3))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 20 FEATURES\")\n",
    "print(\"=\"*70)\n",
    "print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "# Check our engineered feature\n",
    "email_campaign_importance = feature_importance[\n",
    "    feature_importance['feature'] == 'Email_Campaign_Interaction'\n",
    "]\n",
    "if not email_campaign_importance.empty:\n",
    "    rank = feature_importance.index[feature_importance['feature'] == 'Email_Campaign_Interaction'].tolist()[0] + 1\n",
    "    print(f\"\\nüìä Email_Campaign_Interaction:\")\n",
    "    print(f\"   Importance: {email_campaign_importance['importance'].values[0]:.6f}\")\n",
    "    print(f\"   Rank: #{rank} out of {len(feature_cols)}\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Your original best XGBoost:     F1 = 0.8185\")\n",
    "print(f\"Today's baseline:               F1 = 0.8117\")\n",
    "print(f\"With Email√óCampaign feature:    F1 = 0.8175\")\n",
    "print(f\"Final model (optimized):        F1 = {best_f1:.4f}\")\n",
    "\n",
    "if best_f1 >= 0.8185:\n",
    "    print(f\"\\nüéâ NEW BEST! (+{best_f1 - 0.8185:.4f} improvement)\")\n",
    "    decision = \"SUBMIT THIS MODEL\"\n",
    "elif best_f1 >= 0.8175:\n",
    "    print(f\"\\n‚úÖ Solid performance, close to best\")\n",
    "    decision = \"SUBMIT THIS MODEL OR TRY CLUSTERING\"\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Not better than baseline\")\n",
    "    decision = \"REVERT TO ORIGINAL MODEL (0.8185)\"\n",
    "\n",
    "print(f\"\\nüí° RECOMMENDATION: {decision}\")\n",
    "\n",
    "# Save\n",
    "import pickle\n",
    "with open('xgboost_final.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    \n",
    "df.to_csv('df_final_features.csv')\n",
    "print(\"\\n‚úÖ Saved: xgboost_final.pkl\")\n",
    "print(\"‚úÖ Saved: df_final_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kaggle_venv)",
   "language": "python",
   "name": "kaggle_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
