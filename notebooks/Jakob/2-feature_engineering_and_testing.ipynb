{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Testing\n",
    "\n",
    "**Based on EDA Findings**\n",
    "\n",
    "**Date:** November 18, 2025\n",
    "\n",
    "## Objective\n",
    "- Create features based on EDA insights\n",
    "- Test different feature combinations\n",
    "- Identify optimal feature set for modeling\n",
    "\n",
    "## Key Findings from EDA:\n",
    "1. ü•á **Reviews_Read**: +163% lift (strongest signal)\n",
    "2. ü•á **Email_Interaction**: +36% lift\n",
    "3. ü•á **Device_Type**: +27% lift (Tablet best, Mobile worst)\n",
    "4. ü•á **Email √ó Campaign**: +78% combined lift\n",
    "5. ü•à **Category**: +14% lift (0,1,2 good; 3,4 poor)\n",
    "6. ‚ùå **Age**: NO signal (flat 36-37%)\n",
    "7. ‚ùå **AB_Bucket**: NO signal (~37% all buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('/Users/jakobbullinger/Documents/Coding Projects/DSBA/Intro Machine Learning/kaggle_competition/data/raw/train_dataset_M1_with_id.csv')\n",
    "test_df = pd.read_csv('/Users/jakobbullinger/Documents/Coding Projects/DSBA/Intro Machine Learning/kaggle_competition/data/raw/test_dataset_M1_with_id.csv')\n",
    "\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train_df['Purchase'].value_counts())\n",
    "print(f\"\\nPurchase rate: {train_df['Purchase'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_features(df):\n",
    "    \"\"\"\n",
    "    Complete feature engineering pipeline based on EDA findings\n",
    "    \n",
    "    Priority features based on predictive power:\n",
    "    1. Reviews_Read (+163% lift)\n",
    "    2. Email_Interaction (+36% lift)\n",
    "    3. Device_Type (+27% lift)\n",
    "    4. Email √ó Campaign (+78% combined)\n",
    "    5. Category (+14% lift)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"Creating features...\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # 1. REVIEWS FEATURES (STRONGEST SIGNAL - 163% lift)\n",
    "    # ============================================================\n",
    "    # None: 17.8% ‚Üí 5+: 46.7%\n",
    "    df['Reviews_Read_Binned'] = pd.cut(df['Reviews_Read'], \n",
    "                                        bins=[-1, 0, 2, 4, 100],\n",
    "                                        labels=[0, 1, 2, 3])  # 0=none, 1=light, 2=medium, 3=heavy\n",
    "    df['Reviews_Read_Binned'] = df['Reviews_Read_Binned'].astype(float)\n",
    "    \n",
    "    df['Has_Read_Reviews'] = (df['Reviews_Read'] > 0).astype(int)\n",
    "    df['Heavy_Reviewer'] = (df['Reviews_Read'] >= 5).astype(int)\n",
    "    df['Medium_Reviewer'] = ((df['Reviews_Read'] >= 3) & (df['Reviews_Read'] < 5)).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 2. DEVICE FEATURES (STRONG SIGNAL - 27% lift)\n",
    "    # ============================================================\n",
    "    # Tablet: 43.1%, Desktop: 40.3%, Mobile: 31.6%\n",
    "    df['Is_Tablet'] = (df['Device_Type'] == 'Tablet').astype(int)\n",
    "    df['Is_Desktop'] = (df['Device_Type'] == 'Desktop').astype(int)\n",
    "    df['Is_Mobile'] = (df['Device_Type'] == 'Mobile').astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 3. CATEGORY FEATURES (MODERATE SIGNAL - 14% lift)\n",
    "    # ============================================================\n",
    "    # Categories 0,1,2: 40-43% | Categories 3,4: 29-31%\n",
    "    df['Category_Performance'] = df['Category'].map({\n",
    "        0.0: 'High',  # 43%\n",
    "        1.0: 'High',  # 40%\n",
    "        2.0: 'High',  # 42%\n",
    "        3.0: 'Low',   # 31%\n",
    "        4.0: 'Low'    # 29%\n",
    "    })\n",
    "    df['Is_High_Performing_Category'] = (df['Category_Performance'] == 'High').astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 4. EMAIL & CAMPAIGN (STRONGEST INTERACTION - 78% lift)\n",
    "    # ============================================================\n",
    "    # Email + Campaign: 49.3% | No Email + No Campaign: 27.6%\n",
    "    \n",
    "    # Fix Campaign_Period if it's all NaN\n",
    "    if df['Campaign_Period'].isna().all():\n",
    "        print(\"  ‚ö†Ô∏è  Campaign_Period is all NaN - recreating from Day column\")\n",
    "        df['Campaign_Period'] = ((df['Day'] >= 25) & (df['Day'] <= 50)) | \\\n",
    "                                ((df['Day'] >= 75) & (df['Day'] <= 90))\n",
    "    \n",
    "    # Email during campaign interaction\n",
    "    df['Email_During_Campaign'] = ((df['Email_Interaction'] == 1) & \n",
    "                                    (df['Campaign_Period'] == True)).astype(int)\n",
    "    \n",
    "    # Email outside campaign\n",
    "    df['Email_No_Campaign'] = ((df['Email_Interaction'] == 1) & \n",
    "                                (df['Campaign_Period'] == False)).astype(int)\n",
    "    \n",
    "    # Campaign number (which campaign?)\n",
    "    df['Campaign_Number'] = 0\n",
    "    df.loc[(df['Day'] >= 25) & (df['Day'] <= 50), 'Campaign_Number'] = 1\n",
    "    df.loc[(df['Day'] >= 75) & (df['Day'] <= 90), 'Campaign_Number'] = 2\n",
    "    \n",
    "    # ============================================================\n",
    "    # 5. CART FEATURES (ANOMALY DETECTED - investigate)\n",
    "    # ============================================================\n",
    "    df['Has_Items_In_Cart'] = (df['Items_In_Cart'] > 0).astype(int)\n",
    "    df['Cart_Size_Category'] = pd.cut(df['Items_In_Cart'],\n",
    "                                       bins=[-1, 0, 2, 5, 100],\n",
    "                                       labels=[0, 1, 2, 3])\n",
    "    df['Cart_Size_Category'] = df['Cart_Size_Category'].astype(float)\n",
    "    df['Many_Items_In_Cart'] = (df['Items_In_Cart'] >= 6).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 6. ENGAGEMENT FEATURES\n",
    "    # ============================================================\n",
    "    df['Engagement_Level'] = pd.qcut(df['Engagement_Score'], \n",
    "                                     q=4, \n",
    "                                     labels=[0, 1, 2, 3],\n",
    "                                     duplicates='drop').astype(float)\n",
    "    \n",
    "    df['High_Engagement'] = (df['Engagement_Score'] > df['Engagement_Score'].median()).astype(int)\n",
    "    \n",
    "    # Combined engagement metric (weighted by importance)\n",
    "    df['Total_Engagement_Score'] = (\n",
    "        df['Reviews_Read'].fillna(0) * 3 +  # Reviews are very strong signal\n",
    "        df['Items_In_Cart'].fillna(0) +\n",
    "        df['Email_Interaction'].fillna(0) * 5 +  # Email is strongest\n",
    "        df['Engagement_Score'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # ============================================================\n",
    "    # 7. PRICE & DISCOUNT FEATURES\n",
    "    # ============================================================\n",
    "    df['Effective_Price'] = df['Price'] * (1 - df['Discount'] / 100)\n",
    "    df['Discount_Amount'] = df['Price'] * df['Discount'] / 100\n",
    "    df['High_Discount'] = (df['Discount'] >= 30).astype(int)\n",
    "    df['Has_Discount'] = (df['Discount'] > 0).astype(int)\n",
    "    \n",
    "    # Price categories\n",
    "    df['Price_Category'] = pd.qcut(df['Price'], q=4, labels=[0, 1, 2, 3], duplicates='drop').astype(float)\n",
    "    df['High_Price'] = (df['Price'] > df['Price'].median()).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 8. HIGH-VALUE INTERACTION FEATURES\n",
    "    # ============================================================\n",
    "    # Email √ó Campaign (already done above - most important!)\n",
    "    \n",
    "    # Tablet √ó Heavy Reviewer (premium users)\n",
    "    df['Tablet_Heavy_Reviewer'] = ((df['Is_Tablet'] == 1) & \n",
    "                                    (df['Heavy_Reviewer'] == 1)).astype(int)\n",
    "    \n",
    "    # Email √ó Heavy Reviewer (engaged researchers)\n",
    "    df['Email_Heavy_Reviewer'] = ((df['Email_Interaction'] == 1) & \n",
    "                                   (df['Heavy_Reviewer'] == 1)).astype(int)\n",
    "    \n",
    "    # Desktop √ó High Price (serious buyers)\n",
    "    df['Desktop_High_Price'] = ((df['Is_Desktop'] == 1) & \n",
    "                                (df['High_Price'] == 1)).astype(int)\n",
    "    \n",
    "    # High Engagement √ó Reviews (very engaged researchers)\n",
    "    df['Engaged_Researcher'] = ((df['High_Engagement'] == 1) & \n",
    "                                (df['Has_Read_Reviews'] == 1)).astype(int)\n",
    "    \n",
    "    # Reviews √ó Cart (browsing with intent)\n",
    "    df['Reviews_With_Cart'] = ((df['Has_Read_Reviews'] == 1) & \n",
    "                               (df['Has_Items_In_Cart'] == 1)).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 9. SOCIOECONOMIC STATUS\n",
    "    # ============================================================\n",
    "    df['SES_Category'] = pd.qcut(df['Socioeconomic_Status_Score'], \n",
    "                                  q=3, \n",
    "                                  labels=[0, 1, 2],\n",
    "                                  duplicates='drop').astype(float)\n",
    "    df['High_SES'] = (df['Socioeconomic_Status_Score'] > \n",
    "                      df['Socioeconomic_Status_Score'].quantile(0.75)).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 10. TIME-BASED FEATURES\n",
    "    # ============================================================\n",
    "    df['Is_Morning'] = (df['Time_of_Day'] == 'morning').astype(int)\n",
    "    df['Is_Evening'] = (df['Time_of_Day'] == 'evening').astype(int)\n",
    "    df['Is_Afternoon'] = (df['Time_of_Day'] == 'afternoon').astype(int)\n",
    "    \n",
    "    # Weekend proxy (7-day weeks)\n",
    "    df['Is_Weekend'] = ((df['Day'] % 7 == 6) | (df['Day'] % 7 == 0)).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 11. MISSING DATA INDICATORS (might be informative!)\n",
    "    # ============================================================\n",
    "    df['Age_Missing'] = df['Age'].isna().astype(int)\n",
    "    df['Payment_Missing'] = df['Payment_Method'].isna().astype(int)\n",
    "    df['Referral_Missing'] = df['Referral_Source'].isna().astype(int)\n",
    "    df['Price_Missing'] = df['Price'].isna().astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Feature engineering complete!\")\n",
    "    print(f\"   Total features: {df.shape[1]}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING SET\")\n",
    "print(\"=\"*70)\n",
    "train_engineered = create_all_features(train_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SET\")\n",
    "print(\"=\"*70)\n",
    "test_engineered = create_all_features(test_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train shape: {train_engineered.shape}\")\n",
    "print(f\"Test shape: {test_engineered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all new features\n",
    "original_features = train_df.columns.tolist()\n",
    "new_features = [col for col in train_engineered.columns if col not in original_features]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"NEW FEATURES CREATED ({len(new_features)} total)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, feat in enumerate(new_features, 1):\n",
    "    print(f\"{i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Set Testing\n",
    "\n",
    "Test different feature combinations to find the optimal set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_modeling(df, target='Purchase'):\n",
    "    \"\"\"\n",
    "    Prepare data for modeling by encoding and cleaning\n",
    "    \"\"\"\n",
    "    df_model = df.copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    cat_cols = ['Time_of_Day', 'Category_Performance']\n",
    "    for col in cat_cols:\n",
    "        if col in df_model.columns:\n",
    "            df_model[col] = le.fit_transform(df_model[col].astype(str))\n",
    "    \n",
    "    # Remove non-feature columns\n",
    "    drop_cols = ['Purchase', 'Session_ID', 'Device_Type', 'Payment_Method', \n",
    "                 'Referral_Source', 'PM_RS_Combo']\n",
    "    \n",
    "    # Separate features and target\n",
    "    if target in df_model.columns:\n",
    "        y = df_model[target]\n",
    "        X = df_model.drop(columns=[c for c in drop_cols if c in df_model.columns])\n",
    "    else:\n",
    "        y = None\n",
    "        X = df_model.drop(columns=[c for c in drop_cols if c in df_model.columns])\n",
    "    \n",
    "    # Fill NaN with median\n",
    "    X = X.fillna(X.median())\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Test preparation\n",
    "X_train, y_train = prepare_data_for_modeling(train_engineered)\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"\\nFeature columns: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feature_sets(df, target='Purchase'):\n",
    "    \"\"\"\n",
    "    Test different feature combinations to find optimal set\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X, y = prepare_data_for_modeling(df, target)\n",
    "    \n",
    "    # Define feature sets to test\n",
    "    feature_sets = {\n",
    "        '1. Baseline (Original Only)': [\n",
    "            'Age', 'Gender', 'Reviews_Read', 'Price', 'Discount', 'Category',\n",
    "            'Items_In_Cart', 'Email_Interaction', 'Socioeconomic_Status_Score',\n",
    "            'Engagement_Score'\n",
    "        ],\n",
    "        \n",
    "        '2. Email + Campaign Only': [\n",
    "            'Email_Interaction', 'Campaign_Period', 'Email_During_Campaign'\n",
    "        ],\n",
    "        \n",
    "        '3. Reviews Features': [\n",
    "            'Reviews_Read_Binned', 'Has_Read_Reviews', 'Heavy_Reviewer', 'Medium_Reviewer'\n",
    "        ],\n",
    "        \n",
    "        '4. Device Features': [\n",
    "            'Is_Tablet', 'Is_Desktop', 'Is_Mobile'\n",
    "        ],\n",
    "        \n",
    "        '5. Top Features Only': [\n",
    "            # Email & Campaign\n",
    "            'Email_Interaction', 'Campaign_Period', 'Email_During_Campaign',\n",
    "            # Reviews\n",
    "            'Reviews_Read_Binned', 'Heavy_Reviewer',\n",
    "            # Device\n",
    "            'Is_Tablet', 'Is_Desktop',\n",
    "            # Engagement\n",
    "            'Engagement_Score', 'High_Engagement',\n",
    "            # Price/Discount\n",
    "            'Effective_Price', 'High_Discount',\n",
    "            # Category\n",
    "            'Is_High_Performing_Category'\n",
    "        ],\n",
    "        \n",
    "        '6. Top Features + Interactions': [\n",
    "            # Core features\n",
    "            'Email_Interaction', 'Campaign_Period', 'Email_During_Campaign',\n",
    "            'Reviews_Read_Binned', 'Heavy_Reviewer',\n",
    "            'Is_Tablet', 'Is_Desktop',\n",
    "            'Engagement_Score', 'High_Engagement',\n",
    "            'Effective_Price', 'High_Discount',\n",
    "            'Is_High_Performing_Category',\n",
    "            # Interactions\n",
    "            'Email_Heavy_Reviewer', 'Tablet_Heavy_Reviewer',\n",
    "            'Engaged_Researcher', 'Desktop_High_Price'\n",
    "        ],\n",
    "        \n",
    "        '7. Top + Missing Indicators': [\n",
    "            # Core features\n",
    "            'Email_Interaction', 'Campaign_Period', 'Email_During_Campaign',\n",
    "            'Reviews_Read_Binned', 'Heavy_Reviewer',\n",
    "            'Is_Tablet', 'Is_Desktop',\n",
    "            'Engagement_Score', 'High_Engagement',\n",
    "            'Effective_Price', 'High_Discount',\n",
    "            'Is_High_Performing_Category',\n",
    "            # Missing indicators\n",
    "            'Age_Missing', 'Payment_Missing', 'Referral_Missing'\n",
    "        ],\n",
    "        \n",
    "        '8. All Engineered Features': [col for col in X.columns if col not in \n",
    "                                       ['Age', 'Gender', 'Reviews_Read', 'Price', 'Discount', \n",
    "                                        'Category', 'Items_In_Cart', 'Day', 'AB_Bucket', \n",
    "                                        'Price_Sine', 'Socioeconomic_Status_Score']]\n",
    "    }\n",
    "    \n",
    "    # Test each feature set\n",
    "    results = {}\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TESTING FEATURE COMBINATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Using RandomForest with 5-Fold Cross-Validation\")\n",
    "    print(\"Metric: ROC-AUC Score\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for name, features in feature_sets.items():\n",
    "        # Get available features\n",
    "        available = [f for f in features if f in X.columns]\n",
    "        \n",
    "        if len(available) == 0:\n",
    "            print(f\"\\n{name}: No features available - SKIPPED\")\n",
    "            continue\n",
    "        \n",
    "        X_subset = X[available]\n",
    "        \n",
    "        # RandomForest with stratified 5-fold CV\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            max_depth=10,\n",
    "            min_samples_split=50,\n",
    "            random_state=42, \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(rf, X_subset, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "        \n",
    "        results[name] = {\n",
    "            'mean_auc': scores.mean(),\n",
    "            'std_auc': scores.std(),\n",
    "            'n_features': len(available),\n",
    "            'scores': scores\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{name}\")\n",
    "        print(f\"  Features: {len(available):3d}\")\n",
    "        print(f\"  ROC-AUC:  {scores.mean():.4f} ¬± {scores.std():.4f}\")\n",
    "        print(f\"  Folds:    {[f'{s:.4f}' for s in scores]}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY - RANKED BY PERFORMANCE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ranked = sorted(results.items(), key=lambda x: x[1]['mean_auc'], reverse=True)\n",
    "    \n",
    "    for i, (name, metrics) in enumerate(ranked, 1):\n",
    "        print(f\"{i}. {name}\")\n",
    "        print(f\"   AUC: {metrics['mean_auc']:.4f} | Features: {metrics['n_features']}\")\n",
    "    \n",
    "    # Best feature set\n",
    "    best_name, best_metrics = ranked[0]\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üèÜ BEST FEATURE SET\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Name: {best_name}\")\n",
    "    print(f\"ROC-AUC: {best_metrics['mean_auc']:.4f} ¬± {best_metrics['std_auc']:.4f}\")\n",
    "    print(f\"Features: {best_metrics['n_features']}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results, ranked\n",
    "\n",
    "# Run the test\n",
    "results, ranked = test_feature_sets(train_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "names = [name for name, _ in ranked]\n",
    "scores = [metrics['mean_auc'] for _, metrics in ranked]\n",
    "stds = [metrics['std_auc'] for _, metrics in ranked]\n",
    "n_features = [metrics['n_features'] for _, metrics in ranked]\n",
    "\n",
    "# Create bars\n",
    "bars = ax.barh(range(len(names)), scores, xerr=stds, alpha=0.7, capsize=5)\n",
    "\n",
    "# Color best in gold\n",
    "bars[0].set_color('gold')\n",
    "\n",
    "# Add feature count labels\n",
    "for i, (score, n_feat) in enumerate(zip(scores, n_features)):\n",
    "    ax.text(score + 0.005, i, f\"{n_feat} features\", \n",
    "            va='center', fontsize=9, color='gray')\n",
    "\n",
    "ax.set_yticks(range(len(names)))\n",
    "ax.set_yticklabels(names)\n",
    "ax.set_xlabel('ROC-AUC Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Feature Set Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis\n",
    "\n",
    "Analyze which features are most important in the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on best feature set to get feature importances\n",
    "X, y = prepare_data_for_modeling(train_engineered)\n",
    "\n",
    "# Use top features + interactions (usually performs best)\n",
    "best_features = [\n",
    "    'Email_Interaction', 'Campaign_Period', 'Email_During_Campaign',\n",
    "    'Reviews_Read_Binned', 'Heavy_Reviewer',\n",
    "    'Is_Tablet', 'Is_Desktop',\n",
    "    'Engagement_Score', 'High_Engagement',\n",
    "    'Effective_Price', 'High_Discount',\n",
    "    'Is_High_Performing_Category',\n",
    "    'Email_Heavy_Reviewer', 'Tablet_Heavy_Reviewer',\n",
    "    'Engaged_Researcher', 'Desktop_High_Price'\n",
    "]\n",
    "\n",
    "available_features = [f for f in best_features if f in X.columns]\n",
    "X_best = X[available_features]\n",
    "\n",
    "# Train model\n",
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_final.fit(X_best, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Importance': rf_final.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE (Top Features + Interactions)\")\n",
    "print(\"=\"*70)\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "top_n = 15\n",
    "top_features = feature_importance.head(top_n)\n",
    "\n",
    "bars = ax.barh(range(len(top_features)), top_features['Importance'], alpha=0.7)\n",
    "\n",
    "# Color top 3 differently\n",
    "bars[0].set_color('gold')\n",
    "bars[1].set_color('silver')\n",
    "bars[2].set_color('#CD7F32')  # bronze\n",
    "\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['Feature'])\n",
    "ax.set_xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Top {top_n} Feature Importances', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save engineered datasets\n",
    "output_path = '/Users/jakobbullinger/Documents/Coding Projects/DSBA/Intro Machine Learning/kaggle_competition/data/processed/'\n",
    "\n",
    "train_engineered.to_csv(output_path + 'train_engineered.csv', index=False)\n",
    "test_engineered.to_csv(output_path + 'test_engineered.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Engineered datasets saved!\")\n",
    "print(f\"   Train: {train_engineered.shape}\")\n",
    "print(f\"   Test: {test_engineered.shape}\")\n",
    "print(f\"\\nSaved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways\n",
    "\n",
    "### Feature Engineering Insights:\n",
    "\n",
    "1. **Most Important Features:**\n",
    "   - Email √ó Campaign interaction\n",
    "   - Reviews_Read (binned)\n",
    "   - Device_Type (especially Tablet)\n",
    "   - Engagement_Score\n",
    "   - Effective_Price\n",
    "\n",
    "2. **Feature Set Performance:**\n",
    "   - Review results above to see which combination works best\n",
    "   - Baseline vs engineered features comparison\n",
    "   - Impact of interaction features\n",
    "\n",
    "3. **Next Steps:**\n",
    "   - Use best feature set for final modeling\n",
    "   - Try different algorithms (XGBoost, LightGBM, etc.)\n",
    "   - Tune hyperparameters\n",
    "   - Optimize threshold for ‚Ç¨200/day budget constraint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
