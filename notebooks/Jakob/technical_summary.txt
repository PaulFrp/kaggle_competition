
================================================================================
                    MACHINE LEARNING MODEL DEVELOPMENT
                           TECHNICAL ANALYSIS REPORT
================================================================================

DATASET
--------------------------------------------------------------------------------
- Total observations: 13,735
- Features: 50
- Target: Purchase (binary classification)
- Class distribution: 36.8% positive, 63.2% negative
- Data: Pre-cleaned and one-hot encoded by teammate

================================================================================
ANALYSIS WORKFLOW
================================================================================

1. FEATURE ENGINEERING

   Features Created & Tested (15+ variations):
   • Email interaction combinations (Email × Campaign, Email × Engagement)
   • Behavioral ratios (Engagement/Reviews, Reviews/Items)
   • Price-based features (Price per item, discount combinations)
   • Multi-way interactions (3-way email × campaign × engagement)
   • Research depth indicators

   Top Results:
     Feature                        AUC Improvement
     ────────────────────────────────────────────
     Engagement_Per_Review          +0.0011
     Engaged_Research               +0.0010
     Email_Campaign_Referral        +0.0008
     Email_Campaign_Active          +0.0006

   Statistical Validation (10 iterations, 3-fold CV):
     • Engaged_Research: +0.00073 (p=0.063) → Not significant
     • Email_Campaign_Referral: -0.00020 (p=0.402) → Not significant

   Conclusion: No engineered features showed statistically significant 
              improvements. Baseline features already well-optimized.

2. MODEL SELECTION

   Cross-Validation Results (5-fold):

     Model                    Mean AUC    Std Dev    Improvement
     ───────────────────────────────────────────────────────────
     Random Forest            0.9173      ±0.0041    baseline
     XGBoost                  0.9242      ±0.0044    +0.0069
     Gradient Boosting        0.9314      ±0.0023    +0.0141
     LightGBM                 0.9317      ±0.0038    +0.0144 ⭐

   Winner: LightGBM (default parameters)
   Impact: 14x better than best engineered feature

3. HYPERPARAMETER TUNING

   Method: RandomizedSearchCV
   • Iterations: 20 parameter combinations
   • Cross-validation: 5-fold
   • Metric: ROC-AUC

   Parameter Space:
     • n_estimators: [100, 200, 300, 500]
     • max_depth: [3, 5, 7, 10, -1]
     • learning_rate: [0.01, 0.05, 0.1, 0.2]
     • num_leaves: [31, 50, 70, 100]
     • min_child_samples: [20, 30, 50]
     • subsample: [0.7, 0.8, 0.9, 1.0]
     • colsample_bytree: [0.7, 0.8, 0.9, 1.0]

   Best Parameters:
     • subsample: 0.9
     • num_leaves: 50
     • n_estimators: 200
     • min_child_samples: 30
     • max_depth: 3
     • learning_rate: 0.1
     • colsample_bytree: 1.0

   Result: AUC = 0.9342 (+0.0025 vs default LightGBM)

4. THRESHOLD OPTIMIZATION

   Tested thresholds: 0.10 to 0.99 (step: 0.01)
   Evaluation metric: Balance between precision and recall

   Optimal Threshold: 0.60

   Performance at threshold=0.60:
     • Precision: 85.4%
     • Recall: 72.2%
     • F1-Score: 78.3%
     • Percentage of data classified as positive: 31.1%

================================================================================
FINAL MODEL PERFORMANCE
================================================================================

Model: Tuned LightGBM
Threshold: 0.60

Metrics:
  • AUC: 0.9342
  • Precision: 85.4%
  • Recall: 72.2%
  • F1-Score: 78.3%

Performance Progression:
  Random Forest baseline:  0.9173
  → LightGBM default:      0.9317  (+0.0144)
  → LightGBM tuned:        0.9342  (+0.0169 total)

================================================================================
KEY FINDINGS
================================================================================

1. Feature Engineering Impact: Minimal
   • Best feature: +0.0011 AUC (not statistically significant)
   • Baseline features already capture relevant patterns
   • Complex interactions didn't improve performance

2. Model Selection Impact: Significant
   • LightGBM outperformed Random Forest by +0.0144 AUC
   • 14x greater impact than feature engineering
   • Gradient boosting models superior to Random Forest for this dataset

3. Hyperparameter Tuning Impact: Moderate
   • Additional +0.0025 AUC improvement
   • Lower max_depth (3) prevented overfitting
   • Moderate learning rate (0.1) with 200 estimators optimal

4. Methodology Insights:
   • Always validate feature importance with statistical tests
   • Model architecture matters more than feature count
   • Threshold tuning critical for imbalanced classification

================================================================================
