{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Modeling - CLEANED DATA\n",
    "\n",
    "**Team Member:** Jakob Bullinger\n",
    "\n",
    "**Date:** November 18, 2025\n",
    "\n",
    "## Objective\n",
    "- Apply feature engineering to **cleaned data** (from teammate)\n",
    "- Leverage now-usable features: Payment_Method, Referral_Source, Campaign_Period\n",
    "- Test feature combinations and identify optimal set\n",
    "- Prepare for final modeling\n",
    "\n",
    "## Key Insights from Dirty Data Analysis:\n",
    "- **Baseline (dirty):** 0.9118 AUC\n",
    "- **Top features:**\n",
    "  1. Effective_Price (29.7%)\n",
    "  2. Engagement_Score (25.6%)\n",
    "  3. Reviews_Read_Binned (8.5%)\n",
    "  4. Email_Interaction (7.0%)\n",
    "  5. Category_Performance (6.0%)\n",
    "\n",
    "## Expected Improvements with Clean Data:\n",
    "- ‚úÖ Better baseline (0.925-0.940 expected)\n",
    "- ‚úÖ Payment_Method now useful (was 28 variations)\n",
    "- ‚úÖ Referral_Source now useful (was messy)\n",
    "- ‚úÖ Campaign_Period fixed (was all NaN)\n",
    "- ‚úÖ No missing value noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLEANED data\n",
    "# Update these paths to point to your friend's cleaned data\n",
    "train_df = pd.read_csv('/Users/jakobbullinger/Documents/Coding Projects/DSBA/Intro Machine Learning/kaggle_competition/data/processed/train_cleaned.csv')\n",
    "test_df = pd.read_csv('/Users/jakobbullinger/Documents/Coding Projects/DSBA/Intro Machine Learning/kaggle_competition/data/processed/test_cleaned.csv')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA LOADED - CLEANED VERSION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train_df['Purchase'].value_counts())\n",
    "print(f\"Purchase rate: {train_df['Purchase'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Check\n",
    "\n",
    "Verify the cleaning was done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATA QUALITY VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check missing values\n",
    "missing = train_df.isnull().sum()\n",
    "missing_pct = 100 * missing / len(train_df)\n",
    "missing_df = pd.DataFrame({'Missing_Count': missing, 'Percentage': missing_pct})\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: Still have missing values:\")\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"\\n‚úÖ NO MISSING VALUES - Data is fully clean!\")\n",
    "\n",
    "# Check Payment_Method\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PAYMENT_METHOD CHECK\")\n",
    "print(\"=\"*70)\n",
    "print(train_df['Payment_Method'].value_counts())\n",
    "print(f\"\\nUnique values: {train_df['Payment_Method'].nunique()}\")\n",
    "print(\"Expected: 4 (PayPal, Credit, Cash, Bank)\")\n",
    "\n",
    "# Check Referral_Source\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REFERRAL_SOURCE CHECK\")\n",
    "print(\"=\"*70)\n",
    "print(train_df['Referral_Source'].value_counts())\n",
    "print(f\"\\nUnique values: {train_df['Referral_Source'].nunique()}\")\n",
    "print(\"Expected: ~5 (Direct, Email, Social_media, Search_engine, Ads)\")\n",
    "\n",
    "# Check Campaign_Period\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CAMPAIGN_PERIOD CHECK\")\n",
    "print(\"=\"*70)\n",
    "print(train_df['Campaign_Period'].value_counts())\n",
    "print(f\"\\nAny NaN? {train_df['Campaign_Period'].isna().sum()}\")\n",
    "print(\"Expected: TRUE/FALSE with no NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering for Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_clean_data(df):\n",
    "    \"\"\"\n",
    "    Feature engineering for CLEANED data\n",
    "    \n",
    "    Key differences from dirty data version:\n",
    "    - No missing data indicators needed\n",
    "    - Can use Payment_Method (now clean)\n",
    "    - Can use Referral_Source (now clean)\n",
    "    - Campaign_Period already fixed\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"Creating features for clean data...\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # 1. REVIEWS FEATURES (STRONGEST SIGNAL - 163% lift)\n",
    "    # ============================================================\n",
    "    df['Reviews_Read_Binned'] = pd.cut(df['Reviews_Read'], \n",
    "                                        bins=[-1, 0, 2, 4, 100],\n",
    "                                        labels=[0, 1, 2, 3])\n",
    "    df['Reviews_Read_Binned'] = df['Reviews_Read_Binned'].astype(float)\n",
    "    \n",
    "    df['Has_Read_Reviews'] = (df['Reviews_Read'] > 0).astype(int)\n",
    "    df['Heavy_Reviewer'] = (df['Reviews_Read'] >= 5).astype(int)\n",
    "    df['Medium_Reviewer'] = ((df['Reviews_Read'] >= 3) & (df['Reviews_Read'] < 5)).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 2. DEVICE FEATURES (27% lift)\n",
    "    # ============================================================\n",
    "    df['Is_Tablet'] = (df['Device_Type'] == 'Tablet').astype(int)\n",
    "    df['Is_Desktop'] = (df['Device_Type'] == 'Desktop').astype(int)\n",
    "    df['Is_Mobile'] = (df['Device_Type'] == 'Mobile').astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 3. CATEGORY FEATURES (14% lift)\n",
    "    # ============================================================\n",
    "    df['Category_Performance'] = df['Category'].map({\n",
    "        0.0: 'High', 1.0: 'High', 2.0: 'High',\n",
    "        3.0: 'Low', 4.0: 'Low'\n",
    "    })\n",
    "    df['Is_High_Performing_Category'] = (df['Category_Performance'] == 'High').astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 4. EMAIL & CAMPAIGN (78% combined lift)\n",
    "    # ============================================================\n",
    "    df['Email_During_Campaign'] = ((df['Email_Interaction'] == 1) & \n",
    "                                    (df['Campaign_Period'] == True)).astype(int)\n",
    "    df['Email_No_Campaign'] = ((df['Email_Interaction'] == 1) & \n",
    "                                (df['Campaign_Period'] == False)).astype(int)\n",
    "    \n",
    "    df['Campaign_Number'] = 0\n",
    "    df.loc[(df['Day'] >= 25) & (df['Day'] <= 50), 'Campaign_Number'] = 1\n",
    "    df.loc[(df['Day'] >= 75) & (df['Day'] <= 90), 'Campaign_Number'] = 2\n",
    "    \n",
    "    # ============================================================\n",
    "    # 5. PAYMENT METHOD FEATURES (NOW CLEAN!)\n",
    "    # ============================================================\n",
    "    # One-hot encode clean Payment_Method\n",
    "    payment_dummies = pd.get_dummies(df['Payment_Method'], prefix='Payment')\n",
    "    for col in payment_dummies.columns:\n",
    "        df[col] = payment_dummies[col]\n",
    "    \n",
    "    # Digital vs Traditional payment\n",
    "    digital_payments = ['PayPal', 'Credit', 'credit', 'paypal']\n",
    "    df['Digital_Payment'] = df['Payment_Method'].isin(digital_payments).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 6. REFERRAL SOURCE FEATURES (NOW CLEAN!)\n",
    "    # ============================================================\n",
    "    # One-hot encode clean Referral_Source\n",
    "    referral_dummies = pd.get_dummies(df['Referral_Source'], prefix='Referral')\n",
    "    for col in referral_dummies.columns:\n",
    "        df[col] = referral_dummies[col]\n",
    "    \n",
    "    # Channel categories\n",
    "    organic_sources = ['Direct', 'Search_engine', 'direct', 'search_engine']\n",
    "    paid_sources = ['Ads', 'Email', 'ads', 'email']\n",
    "    \n",
    "    df['Organic_Traffic'] = df['Referral_Source'].isin(organic_sources).astype(int)\n",
    "    df['Paid_Traffic'] = df['Referral_Source'].isin(paid_sources).astype(int)\n",
    "    df['Social_Traffic'] = (df['Referral_Source'].str.contains('social', case=False, na=False)).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 7. CART FEATURES\n",
    "    # ============================================================\n",
    "    df['Has_Items_In_Cart'] = (df['Items_In_Cart'] > 0).astype(int)\n",
    "    df['Cart_Size_Category'] = pd.cut(df['Items_In_Cart'],\n",
    "                                       bins=[-1, 0, 2, 5, 100],\n",
    "                                       labels=[0, 1, 2, 3])\n",
    "    df['Cart_Size_Category'] = df['Cart_Size_Category'].astype(float)\n",
    "    df['Many_Items_In_Cart'] = (df['Items_In_Cart'] >= 6).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 8. ENGAGEMENT FEATURES\n",
    "    # ============================================================\n",
    "    df['Engagement_Level'] = pd.qcut(df['Engagement_Score'], \n",
    "                                     q=4, \n",
    "                                     labels=[0, 1, 2, 3],\n",
    "                                     duplicates='drop').astype(float)\n",
    "    df['High_Engagement'] = (df['Engagement_Score'] > df['Engagement_Score'].median()).astype(int)\n",
    "    \n",
    "    # Weighted engagement score\n",
    "    df['Total_Engagement_Score'] = (\n",
    "        df['Reviews_Read'] * 3 +\n",
    "        df['Items_In_Cart'] +\n",
    "        df['Email_Interaction'] * 5 +\n",
    "        df['Engagement_Score']\n",
    "    )\n",
    "    \n",
    "    # ============================================================\n",
    "    # 9. PRICE & DISCOUNT FEATURES\n",
    "    # ============================================================\n",
    "    df['Effective_Price'] = df['Price'] * (1 - df['Discount'] / 100)\n",
    "    df['Discount_Amount'] = df['Price'] * df['Discount'] / 100\n",
    "    df['High_Discount'] = (df['Discount'] >= 30).astype(int)\n",
    "    df['Has_Discount'] = (df['Discount'] > 0).astype(int)\n",
    "    \n",
    "    df['Price_Category'] = pd.qcut(df['Price'], q=4, labels=[0, 1, 2, 3], duplicates='drop').astype(float)\n",
    "    df['High_Price'] = (df['Price'] > df['Price'].median()).astype(int)\n",
    "    \n",
    "    # Price per item in cart\n",
    "    df['Price_Per_Cart_Item'] = df['Price'] / (df['Items_In_Cart'] + 1)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 10. INTERACTION FEATURES (Selective - only high value)\n",
    "    # ============================================================\n",
    "    # Email √ó Campaign (proven valuable)\n",
    "    # Already created above\n",
    "    \n",
    "    # Reviews √ó Email (engaged researchers)\n",
    "    df['Email_Heavy_Reviewer'] = ((df['Email_Interaction'] == 1) & \n",
    "                                   (df['Heavy_Reviewer'] == 1)).astype(int)\n",
    "    \n",
    "    # Device √ó Reviews\n",
    "    df['Tablet_Heavy_Reviewer'] = ((df['Is_Tablet'] == 1) & \n",
    "                                    (df['Heavy_Reviewer'] == 1)).astype(int)\n",
    "    \n",
    "    # High engagement √ó Reviews\n",
    "    df['Engaged_Researcher'] = ((df['High_Engagement'] == 1) & \n",
    "                                (df['Has_Read_Reviews'] == 1)).astype(int)\n",
    "    \n",
    "    # Email referral √ó Email interaction\n",
    "    email_ref_cols = [col for col in df.columns if 'Referral_Email' in col or 'Referral_email' in col]\n",
    "    if len(email_ref_cols) > 0:\n",
    "        df['Email_From_Email_Source'] = ((df[email_ref_cols[0]] == 1) & \n",
    "                                          (df['Email_Interaction'] == 1)).astype(int)\n",
    "    \n",
    "    # Reviews √ó Cart (browsing with intent)\n",
    "    df['Reviews_With_Cart'] = ((df['Has_Read_Reviews'] == 1) & \n",
    "                               (df['Has_Items_In_Cart'] == 1)).astype(int)\n",
    "    \n",
    "    # Desktop √ó High Price (serious buyers)\n",
    "    df['Desktop_High_Price'] = ((df['Is_Desktop'] == 1) & \n",
    "                                (df['High_Price'] == 1)).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 11. SOCIOECONOMIC STATUS\n",
    "    # ============================================================\n",
    "    df['SES_Category'] = pd.qcut(df['Socioeconomic_Status_Score'], \n",
    "                                  q=3, \n",
    "                                  labels=[0, 1, 2],\n",
    "                                  duplicates='drop').astype(float)\n",
    "    df['High_SES'] = (df['Socioeconomic_Status_Score'] > \n",
    "                      df['Socioeconomic_Status_Score'].quantile(0.75)).astype(int)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 12. TIME-BASED FEATURES\n",
    "    # ============================================================\n",
    "    df['Is_Morning'] = (df['Time_of_Day'] == 'morning').astype(int)\n",
    "    df['Is_Evening'] = (df['Time_of_Day'] == 'evening').astype(int)\n",
    "    df['Is_Afternoon'] = (df['Time_of_Day'] == 'afternoon').astype(int)\n",
    "    \n",
    "    df['Is_Weekend'] = ((df['Day'] % 7 == 6) | (df['Day'] % 7 == 0)).astype(int)\n",
    "    df['Week_Number'] = (df['Day'] - 1) // 7 + 1\n",
    "    \n",
    "    print(f\"‚úÖ Feature engineering complete!\")\n",
    "    print(f\"   Total features: {df.shape[1]}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING SET\")\n",
    "print(\"=\"*70)\n",
    "train_engineered = create_features_clean_data(train_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SET\")\n",
    "print(\"=\"*70)\n",
    "test_engineered = create_features_clean_data(test_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train shape: {train_engineered.shape}\")\n",
    "print(f\"Test shape: {test_engineered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List new features\n",
    "original_features = train_df.columns.tolist()\n",
    "new_features = [col for col in train_engineered.columns if col not in original_features]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"NEW FEATURES CREATED ({len(new_features)} total)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Group by type\n",
    "feature_groups = {\n",
    "    'Reviews': [f for f in new_features if 'Review' in f],\n",
    "    'Device': [f for f in new_features if 'Tablet' in f or 'Desktop' in f or 'Mobile' in f],\n",
    "    'Category': [f for f in new_features if 'Category' in f],\n",
    "    'Email & Campaign': [f for f in new_features if 'Email' in f or 'Campaign' in f],\n",
    "    'Payment': [f for f in new_features if 'Payment' in f],\n",
    "    'Referral': [f for f in new_features if 'Referral' in f or 'Traffic' in f],\n",
    "    'Cart': [f for f in new_features if 'Cart' in f],\n",
    "    'Engagement': [f for f in new_features if 'Engagement' in f or 'Engaged' in f],\n",
    "    'Price': [f for f in new_features if 'Price' in f or 'Discount' in f],\n",
    "    'Time': [f for f in new_features if 'Morning' in f or 'Evening' in f or 'Weekend' in f or 'Week' in f],\n",
    "    'SES': [f for f in new_features if 'SES' in f]\n",
    "}\n",
    "\n",
    "for group_name, features in feature_groups.items():\n",
    "    if len(features) > 0:\n",
    "        print(f\"\\n{group_name} Features ({len(features)}):\")\n",
    "        for feat in features:\n",
    "            print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Set Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_modeling(df, target='Purchase'):\n",
    "    \"\"\"\n",
    "    Prepare data for modeling\n",
    "    \"\"\"\n",
    "    df_model = df.copy()\n",
    "    \n",
    "    # Encode remaining categoricals\n",
    "    le = LabelEncoder()\n",
    "    cat_cols = ['Time_of_Day', 'Category_Performance']\n",
    "    for col in cat_cols:\n",
    "        if col in df_model.columns:\n",
    "            df_model[col] = le.fit_transform(df_model[col].astype(str))\n",
    "    \n",
    "    # Remove non-feature columns\n",
    "    drop_cols = ['Purchase', 'Session_ID', 'Device_Type', 'Payment_Method', \n",
    "                 'Referral_Source', 'PM_RS_Combo']\n",
    "    \n",
    "    if target in df_model.columns:\n",
    "        y = df_model[target]\n",
    "        X = df_model.drop(columns=[c for c in drop_cols if c in df_model.columns])\n",
    "    else:\n",
    "        y = None\n",
    "        X = df_model.drop(columns=[c for c in drop_cols if c in df_model.columns])\n",
    "    \n",
    "    # Fill any remaining NaN (shouldn't be many)\n",
    "    if X.isnull().sum().sum() > 0:\n",
    "        print(f\"‚ö†Ô∏è Warning: Found {X.isnull().sum().sum()} NaN values, filling with median\")\n",
    "        X = X.fillna(X.median())\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Test preparation\n",
    "X_train, y_train = prepare_data_for_modeling(train_engineered)\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"\\nTotal features available: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feature_sets_clean(df, target='Purchase'):\n",
    "    \"\"\"\n",
    "    Test feature combinations on CLEAN data\n",
    "    \"\"\"\n",
    "    X, y = prepare_data_for_modeling(df, target)\n",
    "    \n",
    "    # Define feature sets\n",
    "    feature_sets = {\n",
    "        '1. Baseline (Original Clean)': [\n",
    "            'Age', 'Gender', 'Reviews_Read', 'Price', 'Discount', 'Category',\n",
    "            'Items_In_Cart', 'Email_Interaction', 'Socioeconomic_Status_Score',\n",
    "            'Engagement_Score', 'Campaign_Period'\n",
    "        ],\n",
    "        \n",
    "        '2. Baseline + Payment + Referral': [\n",
    "            # Original\n",
    "            'Age', 'Gender', 'Reviews_Read', 'Price', 'Discount', 'Category',\n",
    "            'Items_In_Cart', 'Email_Interaction', 'Socioeconomic_Status_Score',\n",
    "            'Engagement_Score', 'Campaign_Period',\n",
    "            # Now-clean features\n",
    "            'Digital_Payment', 'Organic_Traffic', 'Paid_Traffic', 'Social_Traffic'\n",
    "        ],\n",
    "        \n",
    "        '3. Top Engineered (from dirty data)': [\n",
    "            'Effective_Price', 'Engagement_Score', 'Reviews_Read_Binned',\n",
    "            'Email_Interaction', 'Is_High_Performing_Category',\n",
    "            'Campaign_Period', 'Email_During_Campaign',\n",
    "            'Is_Tablet', 'Is_Desktop', 'High_Discount'\n",
    "        ],\n",
    "        \n",
    "        '4. Top + Payment/Referral': [\n",
    "            # Top from dirty\n",
    "            'Effective_Price', 'Engagement_Score', 'Reviews_Read_Binned',\n",
    "            'Email_Interaction', 'Is_High_Performing_Category',\n",
    "            'Campaign_Period', 'Email_During_Campaign',\n",
    "            'Is_Tablet', 'Is_Desktop', 'High_Discount',\n",
    "            # New clean features\n",
    "            'Digital_Payment', 'Organic_Traffic', 'Paid_Traffic'\n",
    "        ],\n",
    "        \n",
    "        '5. Full Engineered (All New Features)': [\n",
    "            col for col in X.columns \n",
    "            if col not in ['Age', 'Gender', 'Reviews_Read', 'Price', 'Discount',\n",
    "                          'Category', 'Items_In_Cart', 'Day', 'AB_Bucket',\n",
    "                          'Price_Sine', 'Socioeconomic_Status_Score', 'Time_of_Day']\n",
    "        ],\n",
    "        \n",
    "        '6. Everything (Original + Engineered)': X.columns.tolist()\n",
    "    }\n",
    "    \n",
    "    # Test each set\n",
    "    results = {}\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TESTING FEATURE COMBINATIONS ON CLEAN DATA\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Model: RandomForest | CV: 5-Fold Stratified | Metric: ROC-AUC\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for name, features in feature_sets.items():\n",
    "        available = [f for f in features if f in X.columns]\n",
    "        \n",
    "        if len(available) == 0:\n",
    "            print(f\"\\n{name}: No features available - SKIPPED\")\n",
    "            continue\n",
    "        \n",
    "        X_subset = X[available]\n",
    "        \n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=50,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(rf, X_subset, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "        \n",
    "        results[name] = {\n",
    "            'mean_auc': scores.mean(),\n",
    "            'std_auc': scores.std(),\n",
    "            'n_features': len(available),\n",
    "            'scores': scores\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{name}\")\n",
    "        print(f\"  Features: {len(available):3d}\")\n",
    "        print(f\"  ROC-AUC:  {scores.mean():.4f} ¬± {scores.std():.4f}\")\n",
    "        print(f\"  Folds:    {[f'{s:.4f}' for s in scores]}\")\n",
    "    \n",
    "    # Comparison with dirty data baseline\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"IMPROVEMENT VS DIRTY DATA\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Dirty data baseline:  0.9118 AUC\")\n",
    "    print(f\"Clean data baseline:  {results['1. Baseline (Original Clean)']['mean_auc']:.4f} AUC\")\n",
    "    improvement = results['1. Baseline (Original Clean)']['mean_auc'] - 0.9118\n",
    "    print(f\"Improvement:          {improvement:+.4f} ({improvement*100:+.2f}%)\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY - RANKED BY PERFORMANCE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ranked = sorted(results.items(), key=lambda x: x[1]['mean_auc'], reverse=True)\n",
    "    \n",
    "    for i, (name, metrics) in enumerate(ranked, 1):\n",
    "        print(f\"{i}. {name}\")\n",
    "        print(f\"   AUC: {metrics['mean_auc']:.4f} | Features: {metrics['n_features']}\")\n",
    "    \n",
    "    best_name, best_metrics = ranked[0]\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üèÜ BEST FEATURE SET\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Name: {best_name}\")\n",
    "    print(f\"ROC-AUC: {best_metrics['mean_auc']:.4f} ¬± {best_metrics['std_auc']:.4f}\")\n",
    "    print(f\"Features: {best_metrics['n_features']}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results, ranked\n",
    "\n",
    "# Run the test\n",
    "results, ranked = test_feature_sets_clean(train_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "names = [name for name, _ in ranked]\n",
    "scores = [metrics['mean_auc'] for _, metrics in ranked]\n",
    "stds = [metrics['std_auc'] for _, metrics in ranked]\n",
    "n_features = [metrics['n_features'] for _, metrics in ranked]\n",
    "\n",
    "# Create bars\n",
    "bars = ax.barh(range(len(names)), scores, xerr=stds, alpha=0.7, capsize=5)\n",
    "\n",
    "# Color best in gold\n",
    "bars[0].set_color('gold')\n",
    "\n",
    "# Add baseline reference line\n",
    "ax.axvline(x=0.9118, color='red', linestyle='--', linewidth=2, \n",
    "           label='Dirty Data Baseline (0.9118)', alpha=0.7)\n",
    "\n",
    "# Add feature count labels\n",
    "for i, (score, n_feat) in enumerate(zip(scores, n_features)):\n",
    "    ax.text(score + 0.003, i, f\"{n_feat} features\", \n",
    "            va='center', fontsize=9, color='gray')\n",
    "\n",
    "ax.set_yticks(range(len(names)))\n",
    "ax.set_yticklabels(names)\n",
    "ax.set_xlabel('ROC-AUC Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Feature Set Performance - CLEAN DATA', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.legend()\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on best feature set\n",
    "X, y = prepare_data_for_modeling(train_engineered)\n",
    "\n",
    "# Use the best performing feature set from results\n",
    "best_set_name = ranked[0][0]\n",
    "print(f\"Training model on: {best_set_name}\")\n",
    "\n",
    "# Get features for best set\n",
    "if '6. Everything' in best_set_name:\n",
    "    best_features = X.columns.tolist()\n",
    "else:\n",
    "    # Use Top + Payment/Referral as default\n",
    "    best_features = [\n",
    "        'Effective_Price', 'Engagement_Score', 'Reviews_Read_Binned',\n",
    "        'Email_Interaction', 'Is_High_Performing_Category',\n",
    "        'Campaign_Period', 'Email_During_Campaign',\n",
    "        'Is_Tablet', 'Is_Desktop', 'High_Discount',\n",
    "        'Digital_Payment', 'Organic_Traffic', 'Paid_Traffic'\n",
    "    ]\n",
    "\n",
    "available_features = [f for f in best_features if f in X.columns]\n",
    "X_best = X[available_features]\n",
    "\n",
    "# Train model\n",
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_final.fit(X_best, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Importance': rf_final.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE - CLEAN DATA\")\n",
    "print(\"=\"*70)\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Compare with dirty data importances\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: DIRTY vs CLEAN DATA TOP 5\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nDirty Data:\")\n",
    "print(\"  1. Effective_Price       (29.7%)\")\n",
    "print(\"  2. Engagement_Score      (25.6%)\")\n",
    "print(\"  3. Reviews_Read_Binned   (8.5%)\")\n",
    "print(\"  4. Email_Interaction     (7.0%)\")\n",
    "print(\"  5. Category_Performance  (6.0%)\")\n",
    "print(\"\\nClean Data:\")\n",
    "for i, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"  {i+1}. {row['Feature']:<25} ({row['Importance']*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "top_n = 20\n",
    "top_features = feature_importance.head(top_n)\n",
    "\n",
    "bars = ax.barh(range(len(top_features)), top_features['Importance'], alpha=0.7)\n",
    "\n",
    "# Color top 3\n",
    "bars[0].set_color('gold')\n",
    "bars[1].set_color('silver')\n",
    "bars[2].set_color('#CD7F32')\n",
    "\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['Feature'])\n",
    "ax.set_xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Top {top_n} Feature Importances - CLEAN DATA', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Engineered Data & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save engineered datasets\n",
    "output_path = '/Users/jakobbullinger/Documents/Coding Projects/DSBA/Intro Machine Learning/kaggle_competition/data/processed/'\n",
    "\n",
    "train_engineered.to_csv(output_path + 'train_engineered_clean.csv', index=False)\n",
    "test_engineered.to_csv(output_path + 'test_engineered_clean.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Engineered datasets saved!\")\n",
    "print(f\"   Train: {train_engineered.shape}\")\n",
    "print(f\"   Test: {test_engineered.shape}\")\n",
    "print(f\"\\nSaved to: {output_path}\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv(output_path + 'feature_importance_clean.csv', index=False)\n",
    "print(f\"\\n‚úÖ Feature importance saved to: {output_path}feature_importance_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best feature list for modeling\n",
    "best_features_df = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Importance': rf_final.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "best_features_df.to_csv(output_path + 'best_features_for_modeling.csv', index=False)\n",
    "print(f\"‚úÖ Best features list saved for modeling\")\n",
    "print(f\"   Use these {len(available_features)} features in your final model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary & Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "**Performance Improvement:**\n",
    "- Dirty data baseline: 0.9118 AUC\n",
    "- Clean data baseline: [Check results above]\n",
    "- Best feature set: [Check results above]\n",
    "\n",
    "**Most Important Features (Clean Data):**\n",
    "- [Check feature importance output above]\n",
    "\n",
    "**New Insights from Clean Data:**\n",
    "- Payment_Method impact: [Analyze from importance]\n",
    "- Referral_Source impact: [Analyze from importance]\n",
    "- Did cleaning help? [Compare baselines]\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Model Selection:**\n",
    "   - Test XGBoost, LightGBM, Gradient Boosting\n",
    "   - Try ensemble methods\n",
    "   - Compare with Logistic Regression\n",
    "\n",
    "2. **Hyperparameter Tuning:**\n",
    "   - GridSearch or RandomSearch\n",
    "   - Optimize for ROC-AUC\n",
    "   - Consider class weights for imbalance\n",
    "\n",
    "3. **Business Constraint Optimization:**\n",
    "   - Set threshold to target ‚Ç¨200/day budget\n",
    "   - Maximize purchases within budget\n",
    "   - Calculate cost per conversion\n",
    "\n",
    "4. **Marketing Playbook:**\n",
    "   - Extract 3-5 simple rules from top features\n",
    "   - Define customer segments to target\n",
    "   - Create actionable recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
